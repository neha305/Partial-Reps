{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vRJ0wy0DRnRf",
    "outputId": "6a58654d-a05b-4336-f569-ada6c9622cf5"
   },
   "outputs": [],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad_GUNA6Efnc",
    "outputId": "0881ece2-debc-4e14-cbe1-33dd8893480e"
   },
   "outputs": [],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XmgDUOPDF7ro",
    "outputId": "5984deef-a39e-47fc-ba47-61636855ae3e"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atx796ygInhn"
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQKIvvwhEfno"
   },
   "outputs": [],
   "source": [
    "token = \"YourTokenHere\"\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZBXsMQSSGeF"
   },
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 746,
     "referenced_widgets": [
      "2d77811025ec404c8e18878d4b40aac8",
      "8e136c5bcd2846d781c11f08437ef807",
      "ebe82db544d64fd4873b367e680901a9",
      "2c5f6184957a40d58c64e23851ca20b9",
      "96e5ef55849949e79a47475723719760",
      "fe73b068a01a47d1ab12e7f1689be4d6",
      "776b5a87bdc74df99108530a6cfe0dfa",
      "d34da38c73254245a470ef3a56599939",
      "88ff6eb72ee4480782f300b62d76cf86",
      "4696d7973b234c46aeff1757664646be",
      "6c05afc3d343439eaa29f901fecbb129"
     ]
    },
    "id": "HHYUy9D-Efnq",
    "outputId": "e8a5be8c-4197-425f-af12-c3cf33f56e50"
   },
   "outputs": [],
   "source": [
    "model_name = \"meta-llama/Llama-2-7b-chat-hf\" #Running on model LLaMA 2-7B\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token = token)\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "\n",
    "model1 = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config,\n",
    "    device_map=\"auto\", token=token, torch_dtype=torch.float16)\n",
    "device = 'cuda:0' #Change according to device\n",
    "model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ZhjqMxREfnt"
   },
   "outputs": [],
   "source": [
    "path_h = \"/content/datasets/llama_harmful_strings.csv\"\n",
    "path_b = \"/content/datasets/llama_benign.csv\"\n",
    "harmful_dataset = pd.read_csv(path_h)\n",
    "benign_dataset = pd.read_csv(path_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXZjMuFMMUy-",
    "outputId": "138f2282-3e05-4acf-9e05-1911e572d66a"
   },
   "outputs": [],
   "source": [
    "print(harmful_dataset.columns)\n",
    "print(benign_dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOAs-h0mMmKk"
   },
   "outputs": [],
   "source": [
    "harmful_inst = harmful_dataset['instruction'].tolist()\n",
    "harmful_output = harmful_dataset['output'].tolist()\n",
    "benign_inst = benign_dataset['instruction'].tolist()\n",
    "benign_output = benign_dataset['output'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjjfB9utOJ-i"
   },
   "outputs": [],
   "source": [
    "blank_space = tokenizer.encode(\" \", add_special_tokens=False)\n",
    "new_line = tokenizer.encode(\"\\n\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U-dzY0-eLkAK"
   },
   "outputs": [],
   "source": [
    "setup(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "id": "9tDmOtNHi2Px",
    "outputId": "1dd9814e-c684-48c5-a591-9abb7c2a2a4d"
   },
   "outputs": [],
   "source": [
    "b_stats = []\n",
    "with open(\"benign_stats.txt\", \"w\") as f:\n",
    "    f.write(f\"Benign Stats \\n\")\n",
    "for i in range(len(benign_output)):\n",
    "  print(str(i) + \" Start\")\n",
    "  start = time.perf_counter()\n",
    "  gen(model1, tokenizer,benign_output[i], b_stats)\n",
    "  end = time.perf_counter()\n",
    "  elapsed = end - start\n",
    "  print(f\"Sample took {elapsed:.6f} seconds\")\n",
    "  with open(\"benign_stats.txt\", \"a\") as f:\n",
    "    f.write(f\"{[b_stats[-1], elapsed]}\\n\")\n",
    "  print(str(i) + \" End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 949
    },
    "id": "YsseP67O-SrJ",
    "outputId": "b5d878a4-23eb-433e-9fb5-b229ff426633"
   },
   "outputs": [],
   "source": [
    "h_stats = []\n",
    "with open(\"harmful_stats.txt\", \"w\") as f:\n",
    "    f.write(f\"Harmful Stats \\n\")\n",
    "for i in range(len(harmful_output)):\n",
    "  print(str(i) + \" Start\")\n",
    "  start = time.perf_counter()\n",
    "  gen(model1, tokenizer, harmful_output[i], h_stats)\n",
    "  end = time.perf_counter()\n",
    "  elapsed = end - start\n",
    "  print(f\"Sample took {elapsed:.6f} seconds\")\n",
    "  with open(\"harmful_stats.txt\", \"a\") as f:\n",
    "    f.write(f\"{[h_stats[-1], elapsed]}\\n\")\n",
    "  print(str(i) + \" End\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYyDMaTOuURO"
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "for x in h_stats:\n",
    "    if x[3]==False:\n",
    "        c+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FxbeFj-i2Py"
   },
   "outputs": [],
   "source": [
    "print(\"False Negatives: \" + str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9cjSjcELYm7G"
   },
   "outputs": [],
   "source": [
    "b = 0\n",
    "for x in b_stats:\n",
    "    if x[3]==True:\n",
    "        b+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHl420WvYqTq"
   },
   "outputs": [],
   "source": [
    "print(\"False Positives: \" + str(b))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7777774,
     "sourceId": 12337876,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
